package main

var inputParams = map[string][]string{
	"cudnnSetRNNDescriptor_v5":                           {"hiddenSize", "numLayers", "dropoutDesc", "inputMode", "direction", "mode", "dataType"},
	"cudnnFindConvolutionBackwardFilterAlgorithm":        {"handle", "xDesc", "dyDesc", "convDesc", "dwDesc", "requestedAlgoCount"},
	"cudnnGetConvolutionBackwardDataAlgorithm":           {"handle", "wDesc", "dyDesc", "convDesc", "dxDesc", "preference", "memoryLimitInBytes"},
	"cudnnCreateTensorDescriptor":                        {"tensorDesc"},
	"cudnnCTCLoss":                                       {"handle", "probsDesc", "probs", "labels", "labelLengths", "inputLengths", "gradientsDesc", "algo", "ctcLossDesc", "workspace", "sizeInBytes"},
	"cudnnGetCTCLossDescriptor":                          {"ctcLossDesc"},
	"cudnnGetReduceTensorDescriptor":                     {"reduceTensorDesc", "reduceTensorNanOpt"},
	"cudnnSoftmaxBackward":                               {"handle", "algorithm", "mode", "alpha", " beta", "yDesc", "y", "dyDesc", "dy", "dxDesc"},
	"cudnnGetReductionWorkspaceSize":                     {"handle", "reduceDesc", "aDesc", "cDesc"},
	"cudnnSpatialTfSamplerBackward":                      {"handle", "stDesc", "alpha", "beta", "xDesc", "x", "dxDesc", "alphaDgrid", "betaDgrid", "dyDesc", "dy", "grid"},
	"cudnnDeriveBNTensorDescriptor":                      {"xDesc", "mode"},
	"cudnnQueryRuntimeError":                             {"handle", "mode"},
	"cudnnSetReduceTensorDescriptor":                     {"reduceTensorOp", "reduceTensorCompType", "reduceTensorNanOpt", "reduceTensorIndices", "reduceTensorIndicesType"},
	"cudnnOpTensor":                                      {"handle", "opTensorDesc", "alpha1", " alpha2", " beta", "aDesc", " bDesc", " cDesc", "A", " B"},
	"cudnnSetAlgorithmDescriptor":                        {"algorithm"},
	"cudnnFindConvolutionForwardAlgorithm":               {"handle", "xDesc", "wDesc", "convDesc", "yDesc", "requestedAlgoCount"},
	"cudnnConvolutionBiasActivationForward":              {"handle", "alpha1", " alpha2", "xDesc", "x", "wDesc", "w", "convDesc", "algo", "workSpace", "workSpaceSizeInBytes", "zDesc", "z", "biasDesc", "bias", "activationDesc", "yDesc"},
	"cudnnSetFilterNdDescriptor":                         {"datatype", "format", "nbDims", "filterDimA"},
	"cudnnGetConvolutionForwardAlgorithmMaxCount":        {"handle"},
	"cudnnGetOpTensorDescriptor":                         {"opTensorDesc"},
	"cudnnLRNCrossChannelForward":                        {"handle", "normDesc", "lrnMode", "alpha", " beta", "xDesc", " yDesc", "x"},
	"cudnnGetTensor4dDescriptor":                         {"tensorDesc"},
	"cudnnGetPooling2dDescriptor":                        {"poolingDesc"},
	"cudnnFindConvolutionBackwardDataAlgorithmEx":        {"handle", "wDesc", "w", "dyDesc", "dy", "convDesc", "dxDesc", "requestedAlgoCount", "workSpace", "workSpaceSizeInBytes"},
	"cudnnGetActivationDescriptor":                       {"activationDesc"},
	"cudnnSetTensor4dDescriptor":                         {"format", "datatype", "n", "c", "h", "w"},
	"cudnnSpatialTfSamplerForward":                       {"handle", "stDesc", "alpha", "beta", "xDesc", "x", "grid", "yDesc"},
	"cudnnGetPooling2dForwardOutputDim":                  {"poolingDesc", "inputDesc"},
	"cudnnBatchNormalizationForwardTraining":             {"handle", "mode", "alpha", " beta", "xDesc", " yDesc", " x", " y", "bnScaleBiasMeanVarDesc", "bnScale", " bnBias", "exponentialAverageFactor", "epsilon"},
	"cudnnSetCTCLossDescriptor":                          {"compType"},
	"cudnnSoftmaxForward":                                {"handle", "algorithm", "mode", "alpha", " beta", "xDesc", "x", "yDesc"},
	"cudnnGetTensorNdDescriptor":                         {"tensorDesc", "nbDimsRequested", "strideA"},
	"cudnnGetPoolingNdForwardOutputDim":                  {"poolingDesc", "inputDesc", "nbDims"},
	"cudnnSetConvolution2dDescriptor":                    {"pad_h", "pad_w", "u", "v", "dilation_h", "dilation_w", "mode", "computeType"},
	"cudnnPoolingBackward":                               {"handle", "poolingDesc", "alpha", " beta", "yDesc", "y", "dyDesc", "dy", "xDesc", "x", "dxDesc"},
	"cudnnGetAlgorithmSpaceSize":                         {"handle", "algoDesc"},
	"cudnnFindConvolutionForwardAlgorithmEx":             {"handle", "xDesc", "x", "wDesc", "w", "convDesc", "yDesc", "requestedAlgoCount", "workSpace", "workSpaceSizeInBytes"},
	"cudnnScaleTensor":                                   {"handle", "yDesc", "alpha"},
	"cudnnGetConvolutionNdDescriptor":                    {"arrayLengthRequested"},
	"cudnnGetAlgorithmDescriptor":                        {"algorithmDesc", "algorithm"},
	"cudnnSetTensor4dDescriptorEx":                       {"datatype", "n", "c", "h", "w", "nStride", "cStride", "hStride", "wStride"},
	"cudnnSetLRNDescriptor":                              {"lrnN", "lrnAlpha", "lrnBeta", "lrnK"},
	"cudnnGetConvolutionBackwardDataAlgorithmMaxCount":   {"handle"},
	"cudnnGetDropoutDescriptor":                          {"dropoutDesc", "handle"},
	"cudnnSetPoolingNdDescriptor":                        {"mode", "maxpoolingNanOpt", "nbDims"},
	"cudnnAddTensor":                                     {"handle", "alpha", " beta", "aDesc", "A", "cDesc"},
	"cudnnGetStream":                                     {"handle"},
	"cudnnGetCTCLossWorkspaceSize":                       {"handle", "probsDesc", "gradientsDesc", "labels", "labelLengths", "inputLengths", "algo", "ctcLossDesc"},
	"cudnnDivisiveNormalizationBackward":                 {"handle", "normDesc", "mode", "alpha", " beta", "xDesc", " x", " means", "dy", "dxDesc"},
	"cudnnGetConvolutionBackwardFilterAlgorithm":         {"handle", "xDesc", "dyDesc", "convDesc", "dwDesc", "preference", "memoryLimitInBytes"},
	"cudnnSetFilter4dDescriptor":                         {"datatype", "format", "k", "c", "h", "w"},
	"cudnnSpatialTfGridGeneratorBackward":                {"handle", "stDesc", "dgrid"},
	"cudnnIm2Col":                                        {"handle", "srcDesc", "srcData", "filterDesc", "convDesc"},
	"cudnnDestroy":                                       {"handle"},
	"cudnnGetTensorSizeInBytes":                          {"tensorDesc"},
	"cudnnSetTensorNdDescriptorEx":                       {"format", "dataType", "nbDims", "dimA"},
	"cudnnSetOpTensorDescriptor":                         {"opTensorOp", "opTensorCompType", "opTensorNanOpt"},
	"cudnnSetConvolutionNdDescriptor":                    {"arrayLength", "padA", "filterStrideA", "dilationA", "mode", "datatype"},
	"cudnnSaveAlgorithm":                                 {"handle", "algoDesc", "algoSpace", "algoSpaceSizeInBytes"},
	"cudnnSetStream":                                     {"handle", "streamID"},
	"cudnnRNNForwardInference":                           {"handle", "rnnDesc", "seqLength", "xDesc", "x", "hxDesc", "hx", "cxDesc", "cx", "wDesc", "w", "yDesc", "hyDesc", "cyDesc", "workspace", "workSpaceSizeInBytes"},
	"cudnnGetConvolutionBackwardFilterAlgorithmMaxCount": {"handle"},
	"cudnnReduceTensor":                                  {"handle", "reduceTensorDesc", "indicesSizeInBytes", "workspace", "workspaceSizeInBytes", "alpha", " beta", "aDesc", " cDesc", "A"},
	"cudnnGetRNNLinLayerMatrixParams":                    {"handle", "rnnDesc", "pseudoLayer", "xDesc", "wDesc", "w", "linLayerID"},
	"cudnnDestroyOpTensorDescriptor":                     {"opTensorDesc"},
	"cudnnSetCallback":                                   {"mask", "udata", "fptr"},
	"cudnnDestroyReduceTensorDescriptor":                 {"tensorDesc"},
	"cudnnGetFilterNdDescriptor":                         {"wDesc", "nbDimsRequested"},
	"cudnnGetConvolutionBackwardDataAlgorithm_v7":        {"handle", "wDesc", "dyDesc", "convDesc", "dxDesc", "requestedAlgoCount"},
	"cudnnSpatialTfGridGeneratorForward":                 {"handle", "stDesc", "theta"},
	"cudnnGetConvolutionNdForwardOutputDim":              {"convDesc", "inputTensorDesc", "filterDesc", "nbDims"},
	"cudnnDestroyCTCLossDescriptor":                      {"ctcLossDesc"},
	"cudnnActivationBackward":                            {"handle", "activationDesc", "", "alpha", " beta", "yDesc", "y", "dyDesc", "dy", "xDesc", "x", "dxDesc"},
	"cudnnFindConvolutionBackwardDataAlgorithm":          {"handle", "wDesc", "dyDesc", "convDesc", "dxDesc", "requestedAlgoCount"},
	"cudnnSetTensor":                                     {"handle", "yDesc", "valuePtr"},
	"cudnnGetConvolutionForwardAlgorithm_v7":             {"handle", "xDesc", "wDesc", "convDesc", "yDesc", "requestedAlgoCount"},
	"cudnnGetConvolutionBackwardFilterWorkspaceSize":     {"handle", "xDesc", "dyDesc", "convDesc", "dwDesc", "algo"},
	"cudnnSetActivationDescriptor":                       {"mode", "reluNanOpt", "coef"},
	"cudnnFindRNNBackwardDataAlgorithmEx":                {"handle", "rnnDesc", "seqLength", "yDesc", "y", "dyDesc", "dy", "dhyDesc", "dhy", "dcyDesc", "dcy", "wDesc", "w", "hxDesc", "hx", "cxDesc", "cx", "dxDesc", "dhxDesc", "dcxDesc", "findIntensity", "requestedAlgoCount", "workspace", "workSpaceSizeInBytes", "reserveSpaceSizeInBytes"},
	"cudnnConvolutionBackwardFilter":                     {"handle", "alpha", " beta", "xDesc", "x", "dyDesc", "dy", "convDesc", "algo", "workSpace", "workSpaceSizeInBytes", "dwDesc"},
	"cudnnGetConvolutionForwardAlgorithm":                {"handle", "xDesc", "wDesc", "convDesc", "yDesc", "preference", "memoryLimitInBytes"},
	"cudnnGetPoolingNdDescriptor":                        {"poolingDesc", "nbDimsRequested", "maxpoolingNanOpt"},
	"cudnnBatchNormalizationBackward":                    {"handle", "mode", "alphaDataDiff", " betaDataDiff", "alphaParamDiff", " betaParamDiff", "xDesc", " x", " dyDesc", " dy", " dxDesc", " dx", "bnScaleBiasDiffDesc", "bnScale", "epsilon", "savedMean", " savedInvVariance"},
	"cudnnDropoutBackward":                               {"handle", "dropoutDesc", "dyDesc", "dy", "dxDesc", "reserveSpace", "reserveSpaceSizeInBytes"},
	"cudnnDivisiveNormalizationForward":                  {"handle", "normDesc", "divNormMode", "alpha", " beta", "xDesc", " yDesc", "x", "means"},
	"cudnnGetConvolutionBackwardDataWorkspaceSize":       {"handle", "wDesc", "dyDesc", "convDesc", "dxDesc", "algo"},
	"cudnnConvolutionBackwardData":                       {"handle", "alpha", " beta", "wDesc", "w", "dyDesc", "dy", "convDesc", "algo", "workSpace", "workSpaceSizeInBytes", "dxDesc"},
	"cudnnRestoreAlgorithm":                              {"handle", "algoDesc", "algoSpace", "algoSpaceSizeInBytes"},
	"cudnnSetRNNMatrixMathType":                          {"rnnDesc", "mType"},
	"cudnnSetTensorNdDescriptor":                         {"datatype", "nbDims", "dimA", "strideA"},
	"cudnnSetRNNProjectionLayers":                        {"handle", "rnnDesc", "recProjSize", "outProjSize"},
	"cudnnTransformTensor":                               {"handle", "alpha", " beta", "xDesc", "x", "yDesc"},
	"cudnnSetPooling2dDescriptor":                        {"mode", "maxpoolingNanOpt", "windowHeight", "windowWidth", "verticalPadding", "horizontalPadding", "verticalStride", "horizontalStride"},
	"cudnnGetReductionIndicesSize":                       {"handle", "reduceDesc", "aDesc", "cDesc"},
	"cudnnRNNBackwardData":                               {"handle", "rnnDesc", "seqLength", "yDesc", "y", "dyDesc", "dy", "dhyDesc", "dhy", "dcyDesc", "dcy", "wDesc", "w", "hxDesc", "hx", "cxDesc", "cx", "dxDesc", "dhxDesc", "dcxDesc", "workspace", "workSpaceSizeInBytes", "reserveSpaceSizeInBytes"},
	"cudnnGetConvolution2dForwardOutputDim":              {"convDesc", "inputTensorDesc", "filterDesc"},
	"cudnnGetErrorString":                                {"status"},
	"cudnnGetRNNProjectionLayers":                        {"handle", "rnnDesc"},
	"cudnnSetDropoutDescriptor":                          {"handle", "dropout", "stateSizeInBytes", "seed"},
	"cudnnDropoutGetStatesSize":                          {"handle"},
	"cudnnGetRNNParamsSize":                              {"handle", "rnnDesc", "xDesc", "dataType"},
	"cudnnGetConvolutionForwardWorkspaceSize":            {"handle", "xDesc", "wDesc", "convDesc", "yDesc", "algo"},
	"cudnnSetSpatialTransformerNdDescriptor":             {"samplerType", "dataType", "nbDims", "dimA"},
	"cudnnDropoutGetReserveSpaceSize":                    {"xDesc"},
	"cudnnConvolutionBackwardBias":                       {"handle", "alpha", " beta", "dyDesc", "dy", "dbDesc"},
	"cudnnFindRNNForwardTrainingAlgorithmEx":             {"handle", "rnnDesc", "xDesc", "seqLength", "x", "hxDesc", "hx", "cxDesc", "cx", "wDesc", "w", "yDesc", "hyDesc", "cyDesc", "findIntensity", "requestedAlgoCount", "workspace", "workSpaceSizeInBytes", "reserveSpaceSizeInBytes"},
	"cudnnFindRNNBackwardWeightsAlgorithmEx":             {"handle", "rnnDesc", "seqLength", "xDesc", "x", "hxDesc", "hx", "yDesc", "y", "findIntensity", "requestedAlgoCount", "workspace", "workSpaceSizeInBytes", "dwDesc", "reserveSpace", "reserveSpaceSizeInBytes"},
	"cudnnRNNBackwardWeights":                            {"handle", "rnnDesc", "seqLength", "xDesc", "x", "hxDesc", "hx", "yDesc", "y", "workspace", "workSpaceSizeInBytes", "dwDesc", "reserveSpace", "reserveSpaceSizeInBytes"},
	"cudnnDestroyTensorDescriptor":                       {"tensorDesc"},
	"cudnnGetConvolutionBackwardFilterAlgorithm_v7":      {"handle", "xDesc", "dyDesc", "convDesc", "dwDesc", "requestedAlgoCount"},
	"cudnnGetProperty":                                   {"type"},
	"cudnnActivationForward":                             {"handle", "activationDesc", "alpha", " beta", "xDesc", "x", "yDesc"},
	"cudnnGetRNNLinLayerBiasParams":                      {"handle", "rnnDesc", "pseudoLayer", "xDesc", "wDesc", "w", "linLayerID"},
	"cudnnFindRNNForwardInferenceAlgorithmEx":            {"handle", "rnnDesc", "seqLength", "xDesc", "x", "hxDesc", "hx", "cxDesc", "cx", "wDesc", "w", "yDesc", "hyDesc", "cyDesc", "findIntensity", "requestedAlgoCount", "workspace", "workSpaceSizeInBytes"},
	"cudnnPoolingForward":                                {"handle", "poolingDesc", "alpha", " beta", "xDesc", "x", "yDesc"},
	"cudnnFindConvolutionBackwardFilterAlgorithmEx":      {"handle", "xDesc", "x", "dyDesc", "dy", "convDesc", "dwDesc", "requestedAlgoCount", "workSpace", "workSpaceSizeInBytes"},
	"cudnnGetRNNDescriptor":                              {"handle", "rnnDesc"},
	"cudnnLRNCrossChannelBackward":                       {"handle", "normDesc", "lrnMode", "alpha", " beta", "yDesc", " y", "dyDesc", " dy", "xDesc", " x"},
	"cudnnSetRNNDescriptor":                              {"hiddenSize", "numLayers", "dropoutDesc", "inputMode", "direction", "mode", "dataType"},
	"cudnnDropoutForward":                                {"handle", "dropoutDesc", "xDesc", "x", "yDesc", "reserveSpaceSizeInBytes"},
	"cudnnRestoreDropoutDescriptor":                      {"handle", "dropout", "states", "stateSizeInBytes", "seed"},
	"cudnnSetRNNDescriptor_v6":                           {"handle", "hiddenSize", "numLayers", "dropoutDesc", "inputMode", "direction", "mode", "algo", "dataType"},
	"cudnnGetFilter4dDescriptor":                         {"filterDesc"},
	"cudnnRNNForwardTraining":                            {"handle", "rnnDesc", "seqLength", "xDesc", "x", "hxDesc", "hx", "cxDesc", "cx", "wDesc", "w", "yDesc", "hyDesc", "cyDesc", "workspace", "workSpaceSizeInBytes", "reserveSpaceSizeInBytes"},
	"cudnnConvolutionForward":                            {"handle", "alpha", " beta", "xDesc", "x", "wDesc", "w", "convDesc", "algo", "workSpace", "workSpaceSizeInBytes", "yDesc"},
	"cudnnGetRNNWorkspaceSize":                           {"handle", "rnnDesc", "seqLength", "xDesc"},
	"cudnnGetRNNTrainingReserveSize":                     {"handle", "rnnDesc", "seqLength", "xDesc"},
	"cudnnBatchNormalizationForwardInference":            {"handle", "mode", "alpha", " beta", "xDesc", " yDesc", " x", " y", "bnScaleBiasMeanVarDesc", " bnScaleData", " bnBiasData", "estimatedMean", " estimatedVariance", "epsilon"},
}
var outputParams = map[string][]string{
	"cudnnFindConvolutionBackwardFilterAlgorithm":        {"returnedAlgoCount", "perfResults"},
	"cudnnGetConvolutionBackwardDataAlgorithm":           {"algo"},
	"cudnnCTCLoss":                                       {"costs", "gradients"},
	"cudnnGetCTCLossDescriptor":                          {"compType"},
	"cudnnGetReduceTensorDescriptor":                     {"reduceTensorOp", "reduceTensorCompType", "reduceTensorIndices", "reduceTensorIndicesType"},
	"cudnnSoftmaxBackward":                               {"dx"},
	"cudnnGetReductionWorkspaceSize":                     {"sizeInBytes"},
	"cudnnGetConvolution2dDescriptor":                    {"pad_h", "pad_w", "u", "v", "dilation_h", "dilation_w", "mode", "computeType"},
	"cudnnSpatialTfSamplerBackward":                      {"dx", "dgrid"},
	"cudnnDeriveBNTensorDescriptor":                      {"derivedBnDesc"},
	"cudnnQueryRuntimeError":                             {"rstatus"},
	"cudnnFindConvolutionForwardAlgorithm":               {"returnedAlgoCount", "perfResults"},
	"cudnnGetConvolutionForwardAlgorithmMaxCount":        {"count"},
	"cudnnGetOpTensorDescriptor":                         {"opTensorOp", "opTensorCompType", "opTensorNanOpt"},
	"cudnnLRNCrossChannelForward":                        {"y"},
	"cudnnGetTensor4dDescriptor":                         {"datatype", "n", "c", "h", "w", "nStride", "cStride", "hStride", "wStride"},
	"cudnnGetPooling2dDescriptor":                        {"mode", "maxpoolingNanOpt", "windowHeight", "windowWidth", "verticalPadding", "horizontalPadding", "verticalStride", "horizontalStride"},
	"cudnnGetLRNDescriptor":                              {"normDesc", "lrnN", " lrnAlpha", " lrnBeta", " lrnK"},
	"cudnnFindConvolutionBackwardDataAlgorithmEx":        {"returnedAlgoCount", "perfResults"},
	"cudnnGetActivationDescriptor":                       {"mode", "reluNanOpt", "coef"},
	"cudnnSpatialTfSamplerForward":                       {"y"},
	"cudnnGetPooling2dForwardOutputDim":                  {"N", "C", "H", "W"},
	"cudnnBatchNormalizationForwardTraining":             {"resultSaveMean", " resultSaveInvVariance"},
	"cudnnSetCTCLossDescriptor":                          {"ctcLossDesc"},
	"cudnnCreateCTCLossDescriptor":                       {"ctcLossDesc"},
	"cudnnSoftmaxForward":                                {"y"},
	"cudnnGetTensorNdDescriptor":                         {"datatype", "nbDims", "dimA"},
	"cudnnGetPoolingNdForwardOutputDim":                  {"outDimA"},
	"cudnnPoolingBackward":                               {"dx"},
	"cudnnFindConvolutionForwardAlgorithmEx":             {"returnedAlgoCount", "perfResults"},
	"cudnnGetConvolutionNdDescriptor":                    {"arrayLength", "padA", "filterStrideA", "dilationA", "mode", "datatype"},
	"cudnnSetLRNDescriptor":                              {"normDesc"},
	"cudnnGetConvolutionBackwardDataAlgorithmMaxCount":   {"count"},
	"cudnnGetDropoutDescriptor":                          {"dropout", "states", "seed"},
	"cudnnSetPoolingNdDescriptor":                        {"windowDimA", "paddingA", "strideA"},
	"cudnnGetStream":                                     {"streamID"},
	"cudnnGetCTCLossWorkspaceSize":                       {"sizeInBytes"},
	"cudnnDivisiveNormalizationBackward":                 {"dx", " dMeans"},
	"cudnnGetConvolutionBackwardFilterAlgorithm":         {"algo"},
	"cudnnSpatialTfGridGeneratorBackward":                {"dtheta"},
	"cudnnGetCallback":                                   {"mask", "udata", "fptr"},
	"cudnnIm2Col":                                        {"colBuffer"},
	"cudnnGetTensorSizeInBytes":                          {"size"},
	"cudnnSetTensorNdDescriptorEx":                       {"tensorDesc"},
	"cudnnSetOpTensorDescriptor":                         {"opTensorDesc"},
	"cudnnRNNForwardInference":                           {"y", "hy", "cy"},
	"cudnnGetAlgorithmPerformance":                       {"algoDesc", "status", "timecoef", "memory"},
	"cudnnGetConvolutionBackwardFilterAlgorithmMaxCount": {"count"},
	"cudnnReduceTensor":                                  {"indices"},
	"cudnnGetRNNLinLayerMatrixParams":                    {"linLayerMatDesc", "linLayerMat"},
	"cudnnGetFilterNdDescriptor":                         {"datatype", "format", "nbDims", "filterDimA"},
	"cudnnGetConvolutionBackwardDataAlgorithm_v7":        {"returnedAlgoCount", "perfResults"},
	"cudnnSpatialTfGridGeneratorForward":                 {"grid"},
	"cudnnGetConvolutionNdForwardOutputDim":              {"tensorOuputDimA"},
	"cudnnActivationBackward":                            {"dx"},
	"cudnnFindConvolutionBackwardDataAlgorithm":          {"returnedAlgoCount", "perfResults"},
	"cudnnGetConvolutionForwardAlgorithm_v7":             {"returnedAlgoCount", "perfResults"},
	"cudnnGetConvolutionBackwardFilterWorkspaceSize":     {"sizeInBytes"},
	"cudnnFindRNNBackwardDataAlgorithmEx":                {"dx", "dhx", "dcx", "returnedAlgoCount", "perfResults"},
	"cudnnGetConvolutionForwardAlgorithm":                {"algo"},
	"cudnnGetPoolingNdDescriptor":                        {"mode", "nbDims", "windowDimA", "paddingA", "strideA"},
	"cudnnBatchNormalizationBackward":                    {"resultBnScaleDiff", " resultBnBiasDiff"},
	"cudnnDropoutBackward":                               {"dx"},
	"cudnnDivisiveNormalizationForward":                  {"y"},
	"cudnnGetConvolutionBackwardDataWorkspaceSize":       {"sizeInBytes"},
	"cudnnTransformTensor":                               {"y"},
	"cudnnGetReductionIndicesSize":                       {"sizeInBytes"},
	"cudnnCreateOpTensorDescriptor":                      {"opTensorDesc"},
	"cudnnRNNBackwardData":                               {"dx", "dhx", "dcx"},
	"cudnnGetConvolution2dForwardOutputDim":              {"n", "c", "h", "w"},
	"cudnnGetRNNProjectionLayers":                        {"recProjSize", "outProjSize"},
	"cudnnSetDropoutDescriptor":                          {"states"},
	"cudnnDropoutGetStatesSize":                          {"sizeInBytes"},
	"cudnnGetRNNParamsSize":                              {"sizeInBytes"},
	"cudnnGetConvolutionForwardWorkspaceSize":            {"sizeInBytes"},
	"cudnnDropoutGetReserveSpaceSize":                    {"sizeInBytes"},
	"cudnnConvolutionBackwardBias":                       {"db"},
	"cudnnFindRNNForwardTrainingAlgorithmEx":             {"y", "hy", "cy", "returnedAlgoCount", "perfResults"},
	"cudnnFindRNNBackwardWeightsAlgorithmEx":             {"returnedAlgoCount", "perfResults"},
	"cudnnGetConvolutionBackwardFilterAlgorithm_v7":      {"returnedAlgoCount", "perfResults"},
	"cudnnGetProperty":                                   {"value"},
	"cudnnActivationForward":                             {"y"},
	"cudnnGetRNNLinLayerBiasParams":                      {"linLayerBiasDesc", "linLayerBias"},
	"cudnnFindRNNForwardInferenceAlgorithmEx":            {"y", "hy", "cy", "returnedAlgoCount", "perfResults"},
	"cudnnPoolingForward":                                {"y"},
	"cudnnFindConvolutionBackwardFilterAlgorithmEx":      {"returnedAlgoCount", "perfResults"},
	"cudnnGetRNNDescriptor":                              {"hiddenSize", "numLayers", "dropoutDesc", "inputMode", "direction", "mode", "algo", "dataType"},
	"cudnnLRNCrossChannelBackward":                       {"dxDesc", " dx"},
	"cudnnDropoutForward":                                {"y", "reserveSpace"},
	"cudnnGetFilter4dDescriptor":                         {"datatype", "format", "k", "c", "h", "w"},
	"cudnnCreate":                                        {"handle"},
	"cudnnRNNForwardTraining":                            {"y", "hy", "cy"},
	"cudnnGetRNNWorkspaceSize":                           {"sizeInBytes"},
	"cudnnGetRNNTrainingReserveSize":                     {"sizeInBytes"},
}
var ioParams = map[string][]string{
	"cudnnSetRNNDescriptor_v5":                      {"rnnDesc"},
	"cudnnGetConvolution2dDescriptor":               {"convDesc"},
	"cudnnQueryRuntimeError":                        {"tag"},
	"cudnnSetReduceTensorDescriptor":                {"reduceTensorDesc"},
	"cudnnOpTensor":                                 {"C"},
	"cudnnSetAlgorithmDescriptor":                   {"algorithmDesc"},
	"cudnnConvolutionBiasActivationForward":         {"y"},
	"cudnnSetFilterNdDescriptor":                    {"filterDesc"},
	"cudnnFindConvolutionBackwardDataAlgorithmEx":   {"dxDesc"},
	"cudnnSetTensor4dDescriptor":                    {"tensorDesc"},
	"cudnnSetConvolution2dDescriptor":               {"convDesc"},
	"cudnnFindConvolutionForwardAlgorithmEx":        {"y"},
	"cudnnScaleTensor":                              {"y"},
	"cudnnGetConvolutionNdDescriptor":               {"convDesc"},
	"cudnnSetTensor4dDescriptorEx":                  {"tensorDesc"},
	"cudnnSetPoolingNdDescriptor":                   {"poolingDesc"},
	"cudnnAddTensor":                                {"C"},
	"cudnnSetFilter4dDescriptor":                    {"filterDesc"},
	"cudnnSetConvolutionNdDescriptor":               {"convDesc"},
	"cudnnGetAlgorithmPerformance":                  {"algoPerf"},
	"cudnnReduceTensor":                             {"C"},
	"cudnnSetTensor":                                {"y"},
	"cudnnSetActivationDescriptor":                  {"activationDesc"},
	"cudnnFindRNNBackwardDataAlgorithmEx":           {"reserveSpace"},
	"cudnnConvolutionBackwardFilter":                {"dw"},
	"cudnnConvolutionBackwardData":                  {"dx"},
	"cudnnSetTensorNdDescriptor":                    {"tensorDesc"},
	"cudnnSetPooling2dDescriptor":                   {"poolingDesc"},
	"cudnnRNNBackwardData":                          {"reserveSpace"},
	"cudnnSetDropoutDescriptor":                     {"dropoutDesc"},
	"cudnnSetSpatialTransformerNdDescriptor":        {"stDesc"},
	"cudnnFindRNNForwardTrainingAlgorithmEx":        {"reserveSpace"},
	"cudnnFindRNNBackwardWeightsAlgorithmEx":        {"dw"},
	"cudnnRNNBackwardWeights":                       {"dw"},
	"cudnnFindConvolutionBackwardFilterAlgorithmEx": {"dw"},
	"cudnnSetRNNDescriptor":                         {"rnnDesc"},
	"cudnnRestoreDropoutDescriptor":                 {"dropoutDesc"},
	"cudnnSetRNNDescriptor_v6":                      {"rnnDesc"},
	"cudnnRNNForwardTraining":                       {"reserveSpace"},
	"cudnnConvolutionForward":                       {"y"},
}
var docs = map[string]string{
	"cudnnSetRNNDescriptor_v5":                           "cudnnSetRNNDescriptor_v5 initializes a previously created RNN descriptor object.",
	"cudnnFindConvolutionBackwardFilterAlgorithm":        "cudnnFindConvolutionBackwardFilterAlgorithm attempts all cuDNN algorithms (including CUDNN_TENSOR_OP_MATH and CUDNN_DEFAULT_MATH versions of algorithms where CUDNN_TENSOR_OP_MATH may be available) for cudnnConvolutionBackwardFilter(), using GPU memory allocated via cudaMalloc(), and outputs performance metrics to a user-allocated array of cudnnConvolutionBwdFilterAlgoPerf_t. These metrics are written in sorted fashion where the first element has the lowest compute time. The total number of resulting algorithms can be queried through the API cudnnGetConvolutionBackwardMaxCount().",
	"cudnnGetConvolutionBackwardDataAlgorithm":           "cudnnGetConvolutionBackwardDataAlgorithm serves as a heuristic for obtaining the best suited algorithm for cudnnConvolutionBackwardData for the given layer specifications. Based on the input preference, this function will either return the fastest algorithm or the fastest algorithm within a given memory limit. For an exhaustive search for the fastest algorithm, please use cudnnFindConvolutionBackwardDataAlgorithm.",
	"cudnnCreateTensorDescriptor":                        "cudnnCreateTensorDescriptor creates a generic tensor descriptor object by allocating the memory needed to hold its opaque structure. The data is initialized to be all zero.",
	"cudnnCTCLoss":                                       "cudnnCTCLoss returns the ctc costs and gradients, given the probabilities and labels.",
	"cudnnGetCTCLossDescriptor":                          "cudnnGetCTCLossDescriptor returns configuration of the passed CTC loss function descriptor.",
	"cudnnGetReduceTensorDescriptor":                     "cudnnGetReduceTensorDescriptor queries a previously initialized reduce tensor descriptor object.",
	"cudnnSoftmaxBackward":                               "cudnnSoftmaxBackward computes the gradient of the softmax function.",
	"cudnnGetReductionWorkspaceSize":                     "cudnnGetReductionWorkspaceSize is a helper function to return the minimum size of the workspace to be passed to the reduction given the input and output tensors.",
	"cudnnGetConvolution2dDescriptor":                    "cudnnGetConvolution2dDescriptor queries a previously initialized 2D convolution descriptor object.",
	"cudnnSpatialTfSamplerBackward":                      "cudnnSpatialTfSamplerBackward computes the gradient of a sampling operation.",
	"cudnnDeriveBNTensorDescriptor":                      "Derives a secondary tensor descriptor for BatchNormalization scale, invVariance, bnBias, bnScale subtensors from the layer's x data descriptor. Use the tensor descriptor produced by this function as the bnScaleBiasMeanVarDesc and bnScaleBiasDiffDesc parameters in Spatial and Per-Activation Batch Normalization forward and backward functions. Resulting dimensions will be 1xC(x1)x1x1 for BATCHNORM_MODE_SPATIAL and 1xC(xD)xHxW for BATCHNORM_MODE_PER_ACTIVATION (parentheses for 5D). For HALF input data type the resulting tensor descriptor will have a FLOAT type. For other data types it will have the same type as the input data.",
	"cudnnQueryRuntimeError":                             "cuDNN library functions perform extensive input argument checking before launching GPU kernels. The last step is to verify that the GPU kernel actually started. When a kernel fails to start, CUDNN_STATUS_EXECUTION_FAILED is returned by the corresponding API call. Typically, after a GPU kernel starts, no runtime checks are performed by the kernel itself -- numerical results are simply written to output buffers.",
	"cudnnSetReduceTensorDescriptor":                     "cudnnSetReduceTensorDescriptor initializes a previously created reduce tensor descriptor object.",
	"cudnnOpTensor":                                      "cudnnOpTensor implements the equation C = op ( alpha1[0] * A, alpha2[0] * B ) + beta[0] * C, given tensors A, B, and C and scaling factors alpha1, alpha2, and beta. The op to use is indicated by the descriptor opTensorDesc. Currently-supported ops are listed by the cudnnOpTensorOp_t enum.",
	"cudnnSetAlgorithmDescriptor":                        "(New for 7.1)",
	"cudnnFindConvolutionForwardAlgorithm":               "cudnnFindConvolutionForwardAlgorithm attempts all cuDNN algorithms (including CUDNN_TENSOR_OP_MATH and CUDNN_DEFAULT_MATH versions of algorithms where CUDNN_TENSOR_OP_MATH may be available) for cudnnConvolutionForward(), using memory allocated via cudaMalloc(), and outputs performance metrics to a user-allocated array of cudnnConvolutionFwdAlgoPerf_t. These metrics are written in sorted fashion where the first element has the lowest compute time. The total number of resulting algorithms can be queried through the API cudnnGetConvolutionForwardMaxCount().",
	"cudnnConvolutionBiasActivationForward":              "cudnnConvolutionBiasActivationForward applies a bias and then an activation to the convolutions or cross-correlations of cudnnConvolutionForward(), returning results in y. The full computation follows the equation y = act ( alpha1 * conv(x) + alpha2 * z + bias ).",
	"cudnnSetFilterNdDescriptor":                         "cudnnSetFilterNdDescriptor initializes a previously created filter descriptor object. Filters layout must be contiguous in memory.",
	"cudnnGetConvolutionForwardAlgorithmMaxCount":        "cudnnGetConvolutionForwardAlgorithmMaxCount returns the maximum number of algorithms which can be returned from cudnnFindConvolutionForwardAlgorithm() and cudnnGetConvolutionForwardAlgorithm_v7(). cudnnGetConvolutionForwardAlgorithmMaxCount is the sum of all algorithms plus the sum of all algorithms with Tensor Core operations supported for the current device.",
	"cudnnGetOpTensorDescriptor":                         "cudnnGetOpTensorDescriptor returns configuration of the passed Tensor Pointwise math descriptor.",
	"cudnnLRNCrossChannelForward":                        "cudnnLRNCrossChannelForward performs the forward LRN layer computation.",
	"cudnnGetTensor4dDescriptor":                         "cudnnGetTensor4dDescriptor queries the parameters of the previouly initialized Tensor4D descriptor object.",
	"cudnnGetPooling2dDescriptor":                        "cudnnGetPooling2dDescriptor queries a previously created 2D pooling descriptor object.",
	"cudnnGetLRNDescriptor":                              "cudnnGetLRNDescriptor retrieves values stored in the previously initialized LRN descriptor object.",
	"cudnnFindConvolutionBackwardDataAlgorithmEx":        "cudnnFindConvolutionBackwardDataAlgorithmEx attempts all cuDNN algorithms (including CUDNN_TENSOR_OP_MATH and CUDNN_DEFAULT_MATH versions of algorithms where CUDNN_TENSOR_OP_MATH may be available) for cudnnConvolutionBackwardData, using user-allocated GPU memory, and outputs performance metrics to a user-allocated array of cudnnConvolutionBwdDataAlgoPerf_t. These metrics are written in sorted fashion where the first element has the lowest compute time. The total number of resulting algorithms can be queried through the API cudnnGetConvolutionBackwardMaxCount().",
	"cudnnGetActivationDescriptor":                       "cudnnGetActivationDescriptor queries a previously initialized generic activation descriptor object.",
	"cudnnSetTensor4dDescriptor":                         "cudnnSetTensor4dDescriptor initializes a previously created generic Tensor descriptor object into a 4D tensor. The strides of the four dimensions are inferred from the format parameter and set in such a way that the data is contiguous in memory with no padding between dimensions.",
	"cudnnSpatialTfSamplerForward":                       "cudnnSpatialTfSamplerForward performs a sampler operation and generates the output tensor using the grid given by the grid generator.",
	"cudnnGetPooling2dForwardOutputDim":                  "cudnnGetPooling2dForwardOutputDim provides the output dimensions of a tensor after 2d pooling has been applied",
	"cudnnBatchNormalizationForwardTraining":             "cudnnBatchNormalizationForwardTraining performs the forward BatchNormalization layer computation for training phase.",
	"cudnnSetCTCLossDescriptor":                          "cudnnSetCTCLossDescriptor sets a CTC loss function descriptor.",
	"cudnnCreateCTCLossDescriptor":                       "cudnnCreateCTCLossDescriptor creates a CTC loss function descriptor. .",
	"cudnnSoftmaxForward":                                "cudnnSoftmaxForward computes the softmax function.",
	"cudnnGetTensorNdDescriptor":                         "cudnnGetTensorNdDescriptor retrieves values stored in a previously initialized Tensor descriptor object.",
	"cudnnGetPoolingNdForwardOutputDim":                  "cudnnGetPoolingNdForwardOutputDim provides the output dimensions of a tensor after Nd pooling has been applied",
	"cudnnSetConvolution2dDescriptor":                    "cudnnSetConvolution2dDescriptor initializes a previously created convolution descriptor object into a 2D correlation. cudnnSetConvolution2dDescriptor assumes that the tensor and filter descriptors corresponds to the formard convolution path and checks if their settings are valid. That same convolution descriptor can be reused in the backward path provided it corresponds to the same layer.",
	"cudnnPoolingBackward":                               "cudnnPoolingBackward computes the gradient of a pooling operation.",
	"cudnnGetAlgorithmSpaceSize":                         "(New for 7.1)",
	"cudnnFindConvolutionForwardAlgorithmEx":             "cudnnFindConvolutionForwardAlgorithmEx attempts all available cuDNN algorithms (including CUDNN_TENSOR_OP_MATH and CUDNN_DEFAULT_MATH versions of algorithms where CUDNN_TENSOR_OP_MATH may be available) for cudnnConvolutionForward, using user-allocated GPU memory, and outputs performance metrics to a user-allocated array of cudnnConvolutionFwdAlgoPerf_t. These metrics are written in sorted fashion where the first element has the lowest compute time. The total number of resulting algorithms can be queried through the API cudnnGetConvolutionForwardMaxCount().",
	"cudnnScaleTensor":                                   "cudnnScaleTensor scale all the elements of a tensor by a given factor.",
	"cudnnGetConvolutionNdDescriptor":                    "cudnnGetConvolutionNdDescriptor queries a previously initialized convolution descriptor object.",
	"cudnnGetAlgorithmDescriptor":                        "(New for 7.1)",
	"cudnnSetTensor4dDescriptorEx":                       "cudnnSetTensor4dDescriptorEx initializes a previously created generic Tensor descriptor object into a 4D tensor, similarly to cudnnSetTensor4dDescriptor but with the strides explicitly passed as parameters. cudnnSetTensor4dDescriptorEx can be used to lay out the 4D tensor in any order or simply to define gaps between dimensions.",
	"cudnnSetLRNDescriptor":                              "cudnnSetLRNDescriptor initializes a previously created LRN descriptor object.",
	"cudnnGetConvolutionBackwardDataAlgorithmMaxCount":   "cudnnGetConvolutionBackwardDataAlgorithmMaxCount returns the maximum number of algorithms which can be returned from cudnnFindConvolutionBackwardDataAlgorithm() and cudnnGetConvolutionForwardAlgorithm_v7(). cudnnGetConvolutionBackwardDataAlgorithmMaxCount is the sum of all algorithms plus the sum of all algorithms with Tensor Core operations supported for the current device.",
	"cudnnGetDropoutDescriptor":                          "cudnnGetDropoutDescriptor queries the fields of a previously initialized dropout descriptor.",
	"cudnnSetPoolingNdDescriptor":                        "cudnnSetPoolingNdDescriptor initializes a previously created generic pooling descriptor object.",
	"cudnnAddTensor":                                     "cudnnAddTensor adds the scaled values of a bias tensor to another tensor. Each dimension of the bias tensor A must match the corresponding dimension of the destination tensor C or must be equal to 1. In the latter case, the same value from the bias tensor for those dimensions will be used to blend into the C tensor.",
	"cudnnGetStream":                                     "cudnnGetStream retrieves the user CUDA stream programmed in the cuDNN handle. When the user's CUDA stream was not set in the cuDNN handle, this function reports the null-stream.",
	"cudnnGetCTCLossWorkspaceSize":                       "cudnnGetCTCLossWorkspaceSize returns the amount of GPU memory workspace the user needs to allocate to be able to call cudnnCTCLoss with the specified algorithm. The workspace allocated will then be passed to the routine cudnnCTCLoss.",
	"cudnnDivisiveNormalizationBackward":                 "cudnnDivisiveNormalizationBackward performs the backward DivisiveNormalization layer computation.",
	"cudnnGetConvolutionBackwardFilterAlgorithm":         "cudnnGetConvolutionBackwardFilterAlgorithm serves as a heuristic for obtaining the best suited algorithm for cudnnConvolutionBackwardFilter for the given layer specifications. Based on the input preference, this function will either return the fastest algorithm or the fastest algorithm within a given memory limit. For an exhaustive search for the fastest algorithm, please use cudnnFindConvolutionBackwardFilterAlgorithm.",
	"cudnnSetFilter4dDescriptor":                         "cudnnSetFilter4dDescriptor initializes a previously created filter descriptor object into a 4D filter. Filters layout must be contiguous in memory.",
	"cudnnSpatialTfGridGeneratorBackward":                "cudnnSpatialTfGridGeneratorBackward computes the gradient of a grid generation operation.",
	"cudnnGetCallback":                                   "(New for 7.1)",
	"cudnnIm2Col":                                        "cudnnIm2Col constructs the A matrix necessary to perform a forward pass of GEMM convolution. cudnnIm2Col A matrix has a height of batch_size*y_height*y_width and width of input_channels*filter_height*filter_width, where batch_size is xDesc's first dimension, y_height/y_width are computed from cudnnGetConvolutionNdForwardOutputDim(), input_channels is xDesc's second dimension, filter_height/filter_width are wDesc's third and fourth dimension. The A matrix is stored in format HW-fully-packed in GPU memory.",
	"cudnnDestroy":                                       "cudnnDestroy releases resources used by the cuDNN handle. cudnnDestroy is usually the last call with a particular handle to the cuDNN handle. Because cudnnCreate allocates some internal resources, the release of those resources by calling cudnnDestroy will implicitly call cudaDeviceSynchronize; therefore, the recommended best practice is to call cudnnCreate/cudnnDestroy outside of performance-critical code paths.",
	"cudnnGetTensorSizeInBytes":                          "cudnnGetTensorSizeInBytes returns the size of the tensor in memory in respect to the given descriptor. cudnnGetTensorSizeInBytes can be used to know the amount of GPU memory to be allocated to hold that tensor.",
	"cudnnSetTensorNdDescriptorEx":                       "cudnnSetTensorNdDescriptorEx initializes an n-D tensor descriptor.",
	"cudnnSetOpTensorDescriptor":                         "cudnnSetOpTensorDescriptor initializes a Tensor Pointwise math descriptor.",
	"cudnnSetConvolutionNdDescriptor":                    "cudnnSetConvolutionNdDescriptor initializes a previously created generic convolution descriptor object into a n-D correlation. That same convolution descriptor can be reused in the backward path provided it corresponds to the same layer. The convolution computation will done in the specified dataType, which can be potentially different from the input/output tensors.",
	"cudnnSaveAlgorithm":                                 "(New for 7.1)",
	"cudnnSetStream":                                     "cudnnSetStream sets the user's CUDA stream in the cuDNN handle. The new stream will be used to launch cuDNN GPU kernels or to synchronize to this stream when cuDNN kernels are launched in the internal streams. If the cuDNN library stream is not set, all kernels use the default (NULL) stream. Setting the user stream in the cuDNN handle guarantees the issue-order execution of cuDNN calls and other GPU kernels launched in the same stream.",
	"cudnnRNNForwardInference":                           "cudnnRNNForwardInference executes the recurrent neural network described by rnnDesc with inputs x, hx, cx, weights w and outputs y, hy, cy. workspace is required for intermediate storage. cudnnRNNForwardInference does not store intermediate data required for training; cudnnRNNForwardTraining should be used for that purpose.",
	"cudnnGetAlgorithmPerformance":                       "(New for 7.1)",
	"cudnnGetConvolutionBackwardFilterAlgorithmMaxCount": "cudnnGetConvolutionBackwardFilterAlgorithmMaxCount returns the maximum number of algorithms which can be returned from cudnnFindConvolutionBackwardFilterAlgorithm() and cudnnGetConvolutionForwardAlgorithm_v7(). cudnnGetConvolutionBackwardFilterAlgorithmMaxCount is the sum of all algorithms plus the sum of all algorithms with Tensor Core operations supported for the current device.",
	"cudnnReduceTensor":                                  "cudnnReduceTensor reduces tensor A by implementing the equation C = alpha * reduce op ( A ) + beta * C, given tensors A and C and scaling factors alpha and beta. The reduction op to use is indicated by the descriptor reduceTensorDesc. Currently-supported ops are listed by the cudnnReduceTensorOp_t enum.",
	"cudnnGetRNNLinLayerMatrixParams":                    "cudnnGetRNNLinLayerMatrixParams is used to obtain a pointer and a descriptor of every RNN weight matrix in each pseudo-layer within the recurrent network defined by rnnDesc and its input width specified in xDesc.",
	"cudnnDestroyOpTensorDescriptor":                     "cudnnDestroyOpTensorDescriptor deletes a Tensor Pointwise math descriptor object.",
	"cudnnSetCallback":                                   "(New for 7.1)",
	"cudnnDestroyReduceTensorDescriptor":                 "cudnnDestroyReduceTensorDescriptor destroys a previously created reduce tensor descriptor object. When the input pointer is NULL, this function performs no destroy operation.",
	"cudnnGetFilterNdDescriptor":                         "cudnnGetFilterNdDescriptor queries a previously initialized filter descriptor object.",
	"cudnnGetConvolutionBackwardDataAlgorithm_v7":        "cudnnGetConvolutionBackwardDataAlgorithm_v7 serves as a heuristic for obtaining the best suited algorithm for cudnnConvolutionBackwardData for the given layer specifications. cudnnGetConvolutionBackwardDataAlgorithm_v7 will return all algorithms (including CUDNN_TENSOR_OP_MATH and CUDNN_DEFAULT_MATH versions of algorithms where CUDNN_TENSOR_OP_MATH may be available) sorted by expected (based on internal heuristic) relative performance with fastest being index 0 of perfResults. For an exhaustive search for the fastest algorithm, please use cudnnFindConvolutionBackwardDataAlgorithm. The total number of resulting algorithms can be queried through the API cudnnGetConvolutionBackwardMaxCount().",
	"cudnnSpatialTfGridGeneratorForward":                 "cudnnSpatialTfGridGeneratorForward generates a grid of coordinates in the input tensor corresponding to each pixel from the output tensor.",
	"cudnnGetConvolutionNdForwardOutputDim":              "cudnnGetConvolutionNdForwardOutputDim returns the dimensions of the resulting n-D tensor of a nbDims-2-D convolution, given the convolution descriptor, the input tensor descriptor and the filter descriptor cudnnGetConvolutionNdForwardOutputDim can help to setup the output tensor and allocate the proper amount of memory prior to launch the actual convolution.",
	"cudnnDestroyCTCLossDescriptor":                      "cudnnDestroyCTCLossDescriptor destroys a CTC loss function descriptor object.",
	"cudnnActivationBackward":                            "cudnnActivationBackward computes the gradient of a neuron activation function.",
	"cudnnFindConvolutionBackwardDataAlgorithm":          "cudnnFindConvolutionBackwardDataAlgorithm attempts all cuDNN algorithms (including CUDNN_TENSOR_OP_MATH and CUDNN_DEFAULT_MATH versions of algorithms where CUDNN_TENSOR_OP_MATH may be available) for cudnnConvolutionBackwardData(), using memory allocated via cudaMalloc() and outputs performance metrics to a user-allocated array of cudnnConvolutionBwdDataAlgoPerf_t. These metrics are written in sorted fashion where the first element has the lowest compute time. The total number of resulting algorithms can be queried through the API cudnnGetConvolutionBackwardMaxCount().",
	"cudnnSetTensor":                                     "cudnnSetTensor sets all the elements of a tensor to a given value.",
	"cudnnGetConvolutionForwardAlgorithm_v7":             "cudnnGetConvolutionForwardAlgorithm_v7 serves as a heuristic for obtaining the best suited algorithm for cudnnConvolutionForward for the given layer specifications. cudnnGetConvolutionForwardAlgorithm_v7 will return all algorithms (including CUDNN_TENSOR_OP_MATH and CUDNN_DEFAULT_MATH versions of algorithms where CUDNN_TENSOR_OP_MATH may be available) sorted by expected (based on internal heuristic) relative performance with fastest being index 0 of perfResults. For an exhaustive search for the fastest algorithm, please use cudnnFindConvolutionForwardAlgorithm. The total number of resulting algorithms can be queried through the API cudnnGetConvolutionForwardMaxCount().",
	"cudnnGetConvolutionBackwardFilterWorkspaceSize":     "cudnnGetConvolutionBackwardFilterWorkspaceSize returns the amount of GPU memory workspace the user needs to allocate to be able to call cudnnConvolutionBackwardFilter with the specified algorithm. The workspace allocated will then be passed to the routine cudnnConvolutionBackwardFilter. The specified algorithm can be the result of the call to cudnnGetConvolutionBackwardFilterAlgorithm or can be chosen arbitrarily by the user. Note that not every algorithm is available for every configuration of the input tensor and/or every configuration of the convolution descriptor.",
	"cudnnSetActivationDescriptor":                       "cudnnSetActivationDescriptor initializes a previously created generic activation descriptor object.",
	"cudnnFindRNNBackwardDataAlgorithmEx":                "(New for 7.1)",
	"cudnnConvolutionBackwardFilter":                     "cudnnConvolutionBackwardFilter computes the convolution gradient with respect to filter coefficients using the specified algo, returning results in gradDesc.Scaling factors alpha and beta can be used to scale the input tensor and the output tensor respectively.",
	"cudnnGetConvolutionForwardAlgorithm":                "cudnnGetConvolutionForwardAlgorithm serves as a heuristic for obtaining the best suited algorithm for cudnnConvolutionForward for the given layer specifications. Based on the input preference, this function will either return the fastest algorithm or the fastest algorithm within a given memory limit. For an exhaustive search for the fastest algorithm, please use cudnnFindConvolutionForwardAlgorithm.",
	"cudnnGetPoolingNdDescriptor":                        "cudnnGetPoolingNdDescriptor queries a previously initialized generic pooling descriptor object.",
	"cudnnBatchNormalizationBackward":                    "cudnnBatchNormalizationBackward performs the backward BatchNormalization layer computation.",
	"cudnnDropoutBackward":                               "cudnnDropoutBackward performs backward dropout operation over dy returning results in dx. If during forward dropout operation value from x was propagated to y then during backward operation value from dy will be propagated to dx, otherwise, dx value will be set to 0.",
	"cudnnDivisiveNormalizationForward":                  "cudnnDivisiveNormalizationForward performs the forward spatial DivisiveNormalization layer computation. It divides every value in a layer by the standard deviation of it's spatial neighbors as described in `What is the Best Multi-Stage Architecture for Object Recognition`, Jarrett 2009, Local Contrast Normalization Layer section. Note that Divisive Normalization only implements the x/max(c, sigma_x) portion of the computation, where sigma_x is the variance over the spatial neighborhood of x. The full LCN (Local Contrastive Normalization) computation can be implemented as a two-step process:",
	"cudnnGetConvolutionBackwardDataWorkspaceSize":       "cudnnGetConvolutionBackwardDataWorkspaceSize returns the amount of GPU memory workspace the user needs to allocate to be able to call cudnnConvolutionBackwardData with the specified algorithm. The workspace allocated will then be passed to the routine cudnnConvolutionBackwardData. The specified algorithm can be the result of the call to cudnnGetConvolutionBackwardDataAlgorithm or can be chosen arbitrarily by the user. Note that not every algorithm is available for every configuration of the input tensor and/or every configuration of the convolution descriptor.",
	"cudnnConvolutionBackwardData":                       "cudnnConvolutionBackwardData computes the convolution gradient with respect to the output tensor using the specified algo, returning results in gradDesc. Scaling factors alpha and beta can be used to scale the input tensor and the output tensor respectively.",
	"cudnnRestoreAlgorithm":                              "(New for 7.1)",
	"cudnnSetRNNMatrixMathType":                          "cudnnSetRNNMatrixMathType sets the preferred option to use NVIDIA Tensor Cores accelerators on Volta GPU-s (SM 7.0 or higher). When the mType parameter is CUDNN_TENSOR_OP_MATH, inference and training RNN API-s will attempt use Tensor Cores when weights/biases are of type CUDNN_DATA_HALF or CUDNN_DATA_FLOAT. When RNN weights/biases are stored in the CUDNN_DATA_FLOAT format, the original weights and intermediate results will be down-converted to CUDNN_DATA_HALF before they are used in another recursive iteration.",
	"cudnnSetTensorNdDescriptor":                         "cudnnSetTensorNdDescriptor initializes a previously created generic Tensor descriptor object.",
	"cudnnSetRNNProjectionLayers":                        "(New for 7.1)",
	"cudnnTransformTensor":                               "cudnnTransformTensor copies the scaled data from one tensor to another tensor with a different layout. Those descriptors need to have the same dimensions but not necessarily the same strides. The input and output tensors must not overlap in any way (i.e., tensors cannot be transformed in place). cudnnTransformTensor can be used to convert a tensor with an unsupported format to a supported one.",
	"cudnnSetPooling2dDescriptor":                        "cudnnSetPooling2dDescriptor initializes a previously created generic pooling descriptor object into a 2D description.",
	"cudnnGetReductionIndicesSize":                       "cudnnGetReductionIndicesSize is a helper function to return the minimum size of the index space to be passed to the reduction given the input and output tensors.",
	"cudnnCreateOpTensorDescriptor":                      "cudnnCreateOpTensorDescriptor creates a Tensor Pointwise math descriptor.",
	"cudnnRNNBackwardData":                               "cudnnRNNBackwardData executes the recurrent neural network described by rnnDesc with output gradients dy, dhy, dhc, weights w and input gradients dx, dhx, dcx. workspace is required for intermediate storage. The data in reserveSpace must have previously been generated by cudnnRNNForwardTraining. The same reserveSpace data must be used for future calls to cudnnRNNBackwardWeights if they execute on the same input data.",
	"cudnnGetConvolution2dForwardOutputDim":              "cudnnGetConvolution2dForwardOutputDim returns the dimensions of the resulting 4D tensor of a 2D convolution, given the convolution descriptor, the input tensor descriptor and the filter descriptor cudnnGetConvolution2dForwardOutputDim can help to setup the output tensor and allocate the proper amount of memory prior to launch the actual convolution.",
	"cudnnGetErrorString":                                "cudnnGetErrorString converts the cuDNN status code to a NUL terminated (ASCIIZ) static string. For example, when the input argument is CUDNN_STATUS_SUCCESS, the returned string is `CUDNN_STATUS_SUCCESS`. When an invalid status value is passed to the function, the returned string is `CUDNN_UNKNOWN_STATUS`.",
	"cudnnGetRNNProjectionLayers":                        "(New for 7.1)",
	"cudnnSetDropoutDescriptor":                          "cudnnSetDropoutDescriptor initializes a previously created dropout descriptor object. If states argument is equal to NULL, random number generator states won't be initialized, and only dropout value will be set. No other function should be writing to the memory pointed at by states argument while this function is running. The user is expected not to change memory pointed at by states for the duration of the computation.",
	"cudnnDropoutGetStatesSize":                          "cudnnDropoutGetStatesSize is used to query the amount of space required to store the states of the random number generators used by cudnnDropoutForward function.",
	"cudnnGetRNNParamsSize":                              "cudnnGetRNNParamsSize is used to query the amount of parameter space required to execute the RNN described by rnnDesc with inputs dimensions defined by xDesc.",
	"cudnnGetConvolutionForwardWorkspaceSize":            "cudnnGetConvolutionForwardWorkspaceSize returns the amount of GPU memory workspace the user needs to allocate to be able to call cudnnConvolutionForward with the specified algorithm. The workspace allocated will then be passed to the routine cudnnConvolutionForward. The specified algorithm can be the result of the call to cudnnGetConvolutionForwardAlgorithm or can be chosen arbitrarily by the user. Note that not every algorithm is available for every configuration of the input tensor and/or every configuration of the convolution descriptor.",
	"cudnnSetSpatialTransformerNdDescriptor":             "cudnnSetSpatialTransformerNdDescriptor initializes a previously created generic spatial transformer descriptor object.",
	"cudnnDropoutGetReserveSpaceSize":                    "cudnnDropoutGetReserveSpaceSize is used to query the amount of reserve needed to run dropout with the input dimensions given by xDesc. The same reserve space is expected to be passed to cudnnDropoutForward and cudnnDropoutBackward, and its contents is expected to remain unchanged between cudnnDropoutForward and cudnnDropoutBackward calls.",
	"cudnnConvolutionBackwardBias":                       "cudnnConvolutionBackwardBias computes the convolution function gradient with respect to the bias, which is the sum of every element belonging to the same feature map across all of the images of the input tensor. Therefore, the number of elements produced is equal to the number of features maps of the input tensor.",
	"cudnnFindRNNForwardTrainingAlgorithmEx":             "(New for 7.1)",
	"cudnnFindRNNBackwardWeightsAlgorithmEx":             "(New for 7.1)",
	"cudnnRNNBackwardWeights":                            "cudnnRNNBackwardWeights accumulates weight gradients dw from the recurrent neural network described by rnnDesc with inputs x, hx, and outputs y. The mode of operation in this case is additive, the weight gradients calculated will be added to those already existing in dw. workspace is required for intermediate storage. The data in reserveSpace must have previously been generated by cudnnRNNBackwardData.",
	"cudnnDestroyTensorDescriptor":                       "cudnnDestroyTensorDescriptor destroys a previously created tensor descriptor object. When the input pointer is NULL, this function performs no destroy operation.",
	"cudnnGetConvolutionBackwardFilterAlgorithm_v7":      "cudnnGetConvolutionBackwardFilterAlgorithm_v7 serves as a heuristic for obtaining the best suited algorithm for cudnnConvolutionBackwardFilter for the given layer specifications. cudnnGetConvolutionBackwardFilterAlgorithm_v7 will return all algorithms (including CUDNN_TENSOR_OP_MATH and CUDNN_DEFAULT_MATH versions of algorithms where CUDNN_TENSOR_OP_MATH may be available) sorted by expected (based on internal heuristic) relative performance with fastest being index 0 of perfResults. For an exhaustive search for the fastest algorithm, please use cudnnFindConvolutionBackwardFilterAlgorithm. The total number of resulting algorithms can be queried through the API cudnnGetConvolutionBackwardMaxCount().",
	"cudnnGetProperty":                                   "cudnnGetProperty writes a specific part of the cuDNN library version number into the provided host storage.",
	"cudnnActivationForward":                             "cudnnActivationForward applies a specified neuron activation function element-wise over each input value.",
	"cudnnGetRNNLinLayerBiasParams":                      "cudnnGetRNNLinLayerBiasParams is used to obtain a pointer and a descriptor of every RNN bias column vector in each pseudo-layer within the recurrent network defined by rnnDesc and its input width specified in xDesc.",
	"cudnnFindRNNForwardInferenceAlgorithmEx":            "(New for 7.1)",
	"cudnnPoolingForward":                                "cudnnPoolingForward computes pooling of input values (i.e., the maximum or average of several adjacent values) to produce an output with smaller height and/or width.",
	"cudnnFindConvolutionBackwardFilterAlgorithmEx":      "cudnnFindConvolutionBackwardFilterAlgorithmEx attempts all cuDNN algorithms (including CUDNN_TENSOR_OP_MATH and CUDNN_DEFAULT_MATH versions of algorithms where CUDNN_TENSOR_OP_MATH may be available) for cudnnConvolutionBackwardFilter, using user-allocated GPU memory, and outputs performance metrics to a user-allocated array of cudnnConvolutionBwdFilterAlgoPerf_t. These metrics are written in sorted fashion where the first element has the lowest compute time. The total number of resulting algorithms can be queried through the API cudnnGetConvolutionBackwardMaxCount().",
	"cudnnGetRNNDescriptor":                              "cudnnGetRNNDescriptor retrieves RNN network parameters that were configured by cudnnSetRNNDescriptor(). All pointers passed to the function should be not-NULL or CUDNN_STATUS_BAD_PARAM is reported. The function does not check the validity of retrieved network parameters. The parameters are verified when they are written to the RNN descriptor.",
	"cudnnLRNCrossChannelBackward":                       "cudnnLRNCrossChannelBackward performs the backward LRN layer computation.",
	"cudnnSetRNNDescriptor":                              "cudnnSetRNNDescriptor initializes a previously created RNN descriptor object.",
	"cudnnDropoutForward":                                "cudnnDropoutForward performs forward dropout operation over x returning results in y. If dropout was used as a parameter to cudnnSetDropoutDescriptor, the approximately dropout fraction of x values will be replaces by 0, and the rest will be scaled by 1/(1-dropout) cudnnDropoutForward should not be running concurrently with another cudnnDropoutForward function using the same states.",
	"cudnnRestoreDropoutDescriptor":                      "cudnnRestoreDropoutDescriptor restores a dropout descriptor to a previously saved-off state.",
	"cudnnSetRNNDescriptor_v6":                           "cudnnSetRNNDescriptor_v6 initializes a previously created RNN descriptor object.",
	"cudnnGetFilter4dDescriptor":                         "cudnnGetFilter4dDescriptor queries the parameters of the previouly initialized filter descriptor object.",
	"cudnnCreate":                                        "cudnnCreate initializes the cuDNN library and creates a handle to an opaque structure holding the cuDNN library context. It allocates hardware resources on the host and device and must be called prior to making any other cuDNN library calls. The cuDNN library handle is tied to the current CUDA device (context). To use the library on multiple devices, one cuDNN handle needs to be created for each device. For a given device, multiple cuDNN handles with different configurations (e.g., different current CUDA streams) may be created. Because cudnnCreate allocates some internal resources, the release of those resources by calling cudnnDestroy will implicitly call cudaDeviceSynchronize; therefore, the recommended best practice is to call cudnnCreate/cudnnDestroy outside of performance-critical code paths. For multithreaded applications that use the same device from different threads, the recommended programming model is to create one (or a few, as is convenient) cuDNN handle(s) per thread and use that cuDNN handle for the entire life of the thread.",
	"cudnnRNNForwardTraining":                            "cudnnRNNForwardTraining executes the recurrent neural network described by rnnDesc with inputs x, hx, cx, weights w and outputs y, hy, cy. workspace is required for intermediate storage. reserveSpace stores data required for training. The same reserveSpace data must be used for future calls to cudnnRNNBackwardData and cudnnRNNBackwardWeights if these execute on the same input data.",
	"cudnnConvolutionForward":                            "cudnnConvolutionForward executes convolutions or cross-correlations over x using filters specified with w, returning results in y. Scaling factors alpha and beta can be used to scale the input tensor and the output tensor respectively.",
	"cudnnGetRNNWorkspaceSize":                           "cudnnGetRNNWorkspaceSize is used to query the amount of work space required to execute the RNN described by rnnDesc with inputs dimensions defined by xDesc.",
	"cudnnGetRNNTrainingReserveSize":                     "cudnnGetRNNTrainingReserveSize is used to query the amount of reserved space required for training the RNN described by rnnDesc with inputs dimensions defined by xDesc. The same reserved space buffer must be passed to cudnnRNNForwardTraining, cudnnRNNBackwardData and cudnnRNNBackwardWeights. Each of these calls overwrites the contents of the reserved space, however it can safely be backed up and restored between calls if reuse of the memory is desired.",
	"cudnnBatchNormalizationForwardInference":            "cudnnBatchNormalizationForwardInference performs the forward BatchNormalization layer computation for inference phase. cudnnBatchNormalizationForwardInference layer is based on the paper `Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift`, S. Ioffe, C. Szegedy, 2015.",
}
